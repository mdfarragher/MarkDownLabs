---
title: "Evaluate The Results"
type: "lesson"
layout: "default"
sortkey: 20
---

Now let's evaluate the quality of the model by having it generate predictions (called 'Scoring') for the remaining 20% of data in the test partition. Then we'll compare those predictions to the actual median house values, and calculate the regression evaluation metrics.

So imagine you are a realtor in California selling houses. What kind of prediction accuracy would you consider acceptable?

Determine the minimum mean absolute error or root mean square error values you deem acceptable. This will be the target your model needs to beat.
{ .homework }

#### Calculate Evaluation Metrics

Enter the following prompt:

"Use the trained model to create predictions for the test set, and then calculate evaluation metrics for these predictions and print them."
{ .prompt }

That should create the following code:

```csharp
// Use the trained model to create predictions for the test set
Console.WriteLine("Evaluating the model...");
var predictions = model.Transform(testingData);

// Evaluate the model's performance
var metrics = mlContext.Regression.Evaluate(predictions, labelColumnName: nameof(HousingData.MedianHouseValue), scoreColumnName: "Score");

// Print evaluation metrics
Console.WriteLine("Model evaluation metrics:");
Console.WriteLine($"  R-squared: {metrics.RSquared:F4}");
Console.WriteLine($"  Mean Absolute Error: {metrics.MeanAbsoluteError:F4}");
Console.WriteLine($"  Mean Squared Error: {metrics.MeanSquaredError:F4}");
Console.WriteLine($"  Root Mean Squared Error: {metrics.RootMeanSquaredError:F4}");
```

This code calls `Transform` to set up predictions for every single housing block record in the test partition. The `Evaluate` method then compares these predictions to the actual median house prices and automatically calculates these metrics:

- **RSquared**: this is the coefficient of determination, a common evaluation metric for regression models. It tells you how well your model explains the variance in the data, or how good the predictions are compared to simply predicting the mean.
- **RootMeanSquaredError**: this is the root mean squared error or RMSE value. Itâ€™s the go-to metric in the field of machine learning to evaluate models and rate their accuracy. RMSE represents the length of a vector in n-dimensional space, made up of the error in each individual prediction.
- **MeanSquaredError**: this is the mean squared error, or MSE value. Note that RMSE and MSE are related: RMSE is the square root of MSE.
- **MeanAbsoluteError**: this is the mean absolute prediction error or MAE value, expressed in dollars.

Note that the `Evaluate` method refers to two columns:

- `labelColumnName` is the name of the column in the dataset that holds the label. For our California Housing dataset, this is **MedianHouseValue**.
- `scoreColumnName` is the name of the column in the dataset that holds the predictions generated by the `Transform` method. This column is named **Score** and was automatically added.

When I run my code, I see the following:

![Regression Model Evaluation](../img/evaluate.jpg)
{ .img-fluid .mb-4 }

I get the following results:

The R-squared value is **0.6013**. This means the model is able to explain ~60% of the variance in housing prices. This is not bad, it's capturing a majority of the pattern in the data, but still leaves ~40% unexplained. This indicates a moderate-to-strong fit, and for real-world housing data, we could consider this a reasonable result.

The mean absolute error (MAE) is **$42,760**. So on average, the model's predictions are off by about $42k. That's not bad at all, given that the most expensive house in our dataset is $500k.

The mean squared error (MSE) is **~3.65 billion**. Large errors are penalized much more heavily in this metric because of the squaring, so this large number indicates the presence of some high-error predictions.

The root mean squared error (RMSE) is **~$60,439**. This metric is similar to MAE, but gives more weight to large errors. The fact that the RMSE > MAE suggests that the model occasionally makes big errors in its predictions.

So how did your model do?

Compare your model with the target you set earlier. Did it make predictions that beat the target? Decide if you're happy with the predictive quality of your model.
{ .homework }

#### Summary

Evaluation is an essential step in machine learning, because this is where we check if the predictions our model is making are any good. If our model cannot beat the target we set, we'll have to go back to the drawing board and tweak the data transformations or pick a different learning algorithm.

A target of $50k is perfectly reasonable for housing, it means you'll accept a 10% prediction error for houses worth $500k. And the SDCA learning algorithm combined with all the data transformations we discussed was able to beat that target.

For now, we will continue working on our machine learning app. But you'll have an opportunity later to improve the performance of your model.
